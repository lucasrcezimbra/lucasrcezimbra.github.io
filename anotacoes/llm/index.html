<!doctype html><html lang=pt><head><title>LLM · Lucas Cezimbra</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Lucas Cezimbra"><meta name=description content="Vector Database LLM - A CLI utility and Python library for interacting with Large Language Models, including OpenAI, PaLM and local models installed on your own machine. OWASP Top 10 - Doc - Slides ETL for LLMs - https://unstructured.io/ LoRA = low rank adaptation - vastly cheaper mechanism for fine tuning Emerging Architectures for LLM Applications https://github.com/imartinez/privateGPT https://github.com/Stability-AI/StableLM - Stability AI #OpenSource https://github.com/Torantulino/Auto-GPT Transformer for Actions - GPT - https://www."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:image content="https://cezimbra.me/images/lucas-180x180.jpg"><meta name=twitter:title content="LLM"><meta name=twitter:description content="Vector Database LLM - A CLI utility and Python library for interacting with Large Language Models, including OpenAI, PaLM and local models installed on your own machine. OWASP Top 10 - Doc - Slides ETL for LLMs - https://unstructured.io/ LoRA = low rank adaptation - vastly cheaper mechanism for fine tuning Emerging Architectures for LLM Applications https://github.com/imartinez/privateGPT https://github.com/Stability-AI/StableLM - Stability AI #OpenSource https://github.com/Torantulino/Auto-GPT Transformer for Actions - GPT - https://www."><meta name=twitter:site content="@lucasrcezimbra"><meta property="og:title" content="LLM"><meta property="og:description" content="Vector Database LLM - A CLI utility and Python library for interacting with Large Language Models, including OpenAI, PaLM and local models installed on your own machine. OWASP Top 10 - Doc - Slides ETL for LLMs - https://unstructured.io/ LoRA = low rank adaptation - vastly cheaper mechanism for fine tuning Emerging Architectures for LLM Applications https://github.com/imartinez/privateGPT https://github.com/Stability-AI/StableLM - Stability AI #OpenSource https://github.com/Torantulino/Auto-GPT Transformer for Actions - GPT - https://www."><meta property="og:type" content="article"><meta property="og:url" content="https://cezimbra.me/anotacoes/llm/"><meta property="og:image" content="https://cezimbra.me/images/lucas-180x180.jpg"><meta property="article:section" content="anotacoes"><meta property="article:published_time" content="2023-08-15T07:30:00-03:00"><meta property="article:modified_time" content="2023-08-15T07:30:00-03:00"><link rel=canonical href=https://cezimbra.me/anotacoes/llm/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.593028e7f7ac55c003b79c230d1cd411bb4ca53b31556c3abb7f027170e646e9.css integrity="sha256-WTAo5/esVcADt5wjDRzUEbtMpTsxVWw6u38CcXDmRuk=" crossorigin=anonymous media=screen><link rel=stylesheet href=/styles/custom.min.2ef373c2c125094d9302d8a924eba231d053340611b63bcf581460745cef626f.css integrity="sha256-LvNzwsElCU2TAtipJOuiMdBTNAYRtjvPWBRgdFzvYm8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/styles/project.min.b34629645b77ae2432c104397ae29202077f926d712f2019dfa9034bc78837fa.css integrity="sha256-s0YpZFt3riQywQQ5euKSAgd/km1xLyAZ36kDS8eIN/o=" crossorigin=anonymous media=screen><link rel=stylesheet href=/styles/contribution.min.cc4187dd6677d15a0c4438b74294dbe3f54269e14a831b267fb6f02a24f90d5d.css integrity="sha256-zEGH3WZ30VoMRDi3QpTb4/VCaeFKgxsmf7bwKiT5DV0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/styles/jquery.dataTables.min.min.8f6eae843117db9532d2c9b910f3b28834d22d85107ce9aba8b5abbeab67400a.css integrity="sha256-j26uhDEX25Uy0sm5EPOyiDTSLYUQfOmrqLWrvqtnQAo=" crossorigin=anonymous media=screen><link rel=stylesheet href=/styles/timeline.min.801628785543d9e7f6deb109e9561a48da7823522c0986a7dd47be117447e62f.css integrity="sha256-gBYoeFVD2ef23rEJ6VYaSNp4I1IsCYan3Ue+EXRH5i8=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/lucas-32x32.jpg sizes=32x32><link rel=icon type=image/png href=/images/lucas-16x16.jpg sizes=16x16><link rel=apple-touch-icon href=/images/lucas-180x180.jpg><link rel=apple-touch-icon sizes=180x180 href=/images/lucas-180x180.jpg><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.117.0"></head><body class="preload-transitions colorscheme-dark"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Lucas Cezimbra</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/sobre/>Sobre</a></li><li class=navigation-item><a class=navigation-link href=/projetos/>Projetos</a></li><li class=navigation-item><a class=navigation-link href=/anotacoes/indice/>Anotações</a></li><li class=navigation-item><a class=navigation-link href=/palestras/>Palestras</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li></ul></section></nav><div class=content><section class="container page"><article><header><h1 class=title><a class=title-link href=https://cezimbra.me/anotacoes/llm/>LLM</a></h1></header><ul><li><a href=https://cezimbra.me/anotacoes/vector-database/>Vector Database</a></li><li><a href=https://llm.datasette.io/en/stable/>LLM</a> - A CLI utility and <a href=https://cezimbra.me/anotacoes/python/>Python</a> library for interacting with Large Language Models, including OpenAI, PaLM and local models installed on your own machine.</li><li>OWASP Top 10 - <a href=https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_0.pdf>Doc</a> - <a href=https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-slides-v1_0.pdf>Slides</a></li><li>ETL for LLMs - <a href=https://unstructured.io/>https://unstructured.io/</a></li><li>LoRA = low rank adaptation - vastly cheaper mechanism for fine tuning</li><li><a href=https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/>Emerging Architectures for LLM Applications</a></li><li><a href=https://github.com/imartinez/privateGPT>https://github.com/imartinez/privateGPT</a></li><li><a href=https://github.com/Stability-AI/StableLM>https://github.com/Stability-AI/StableLM</a> - Stability AI #OpenSource</li><li><a href=https://github.com/Torantulino/Auto-GPT>https://github.com/Torantulino/Auto-GPT</a></li><li>Transformer for Actions - GPT - <a href=https://www.adept.ai/blog/act-1>https://www.adept.ai/blog/act-1</a></li><li>Toolformer<ul><li>Meta desenvolve modelo de linguagem que aprende sozinho a usar ferramentas externas, como mecanismos de busca, calculadoras e calendários</li><li>Decide por conta própria quais APIs usar para contornar as limitações presentes em outros sistemas, como a falta de conhecimento em aritmética, por exemplo. Seu desempenho é superior ao GPT-3, mesmo sendo baseado no GPT-J, um modelo com apenas 4% dos parâmetros.</li><li><a href=https://arstechnica.com/information-technology/2023/02/meta-develops-an-ai-language-bot-that-can-use-external-software-tools/>https://arstechnica.com/information-technology/2023/02/meta-develops-an-ai-language-bot-that-can-use-external-software-tools/</a></li><li><a href=https://arxiv.org/abs/2302.04761>https://arxiv.org/abs/2302.04761</a></li></ul></li><li><a href=https://github.com/Lightning-AI/lit-llama>https://github.com/Lightning-AI/lit-llama</a> #OpenSource</li></ul><blockquote><p>Good speech-to-text models have this trait, along with language translation programs and on-screen swipe keyboards. In each of these cases we want to be understood, not surprised. AI, therefore, makes the most sense as a translation layer between humans, who are incurably chaotic, and traditional software, which is deterministic.</p><p>an adaptive interface between chaotic real-world problems and secure, well-architected technical solutions. AI may not truly understand us, but it can deliver our intentions to an API with reasonable accuracy and describe the results in a way we understand.</p><p>from <a href=https://stackoverflow.blog/2023/05/01/ai-isnt-the-app-its-the-ui/>https://stackoverflow.blog/2023/05/01/ai-isnt-the-app-its-the-ui/</a></p></blockquote><ul><li><a href=https://gpt-index.readthedocs.io/en/latest/index.html>LlamaIndex</a></li></ul><h2 id=chatgpt>ChatGPT
<a class=heading-link href=#chatgpt><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li>Plugins<ul><li><a href=https://medium.com/geekculture/6-chatgpt-mind-blowing-extensions-to-use-it-anywhere-db6638640ec7>https://medium.com/geekculture/6-chatgpt-mind-blowing-extensions-to-use-it-anywhere-db6638640ec7</a><ul><li><a href=https://github.com/wong2/chat-gpt-google-extension>https://github.com/wong2/chat-gpt-google-extension</a></li><li><a href=https://github.com/gragland/chatgpt-chrome-extension>https://github.com/gragland/chatgpt-chrome-extension</a></li></ul></li><li><a href=https://platform.openai.com/docs/plugins/introduction>https://platform.openai.com/docs/plugins/introduction</a> - Docs</li><li><a href=http://openai.com/waitlist/plugins>http://openai.com/waitlist/plugins</a> - Waitlist</li><li><a href=https://openai.com/blog/chatgpt-plugins#OpenAI>https://openai.com/blog/chatgpt-plugins#OpenAI</a> - Landing Page</li><li><a href=https://github.com/openai/chatgpt-retrieval-plugin>https://github.com/openai/chatgpt-retrieval-plugin</a> - The open-source retrieval plugin enables ChatGPT to access personal or organizational information sources</li></ul></li></ul><h2 id=code-generation>Code generation
<a class=heading-link href=#code-generation><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://github.com/replit/ReplitLM>https://github.com/replit/ReplitLM</a></li><li><a href=https://huggingface.co/blog/starcoder>https://huggingface.co/blog/starcoder</a><ul><li><a href=https://huggingface.co/bigcode/starcoder>https://huggingface.co/bigcode/starcoder</a></li><li><a href="https://marketplace.visualstudio.com/items?itemName=HuggingFace.huggingface-vscode">https://marketplace.visualstudio.com/items?itemName=HuggingFace.huggingface-vscode</a></li></ul></li></ul><h3 id=copilot>Copilot
<a class=heading-link href=#copilot><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><ul><li><a href="https://marketplace.visualstudio.com/items?itemName=gencay.vscode-chatgpt">https://marketplace.visualstudio.com/items?itemName=gencay.vscode-chatgpt</a> - ChatGPT no VSCode</li></ul><h4 id=reverse-enginerring>Reverse enginerring
<a class=heading-link href=#reverse-enginerring><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><ul><li><a href=https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html>https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html</a></li></ul><h2 id=datasets>Datasets
<a class=heading-link href=#datasets><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://pile.eleuther.ai/>https://pile.eleuther.ai/</a> - An 800GB Dataset of Diverse Text for Language Modeling</li><li><a href=https://laion.ai/>https://laion.ai/</a> - Large-scale Artificial Intelligence Open Network - TRULY OPEN AI. 100% NON-PROFIT. 100% FREE.</li></ul><h2 id=hosting>Hosting
<a class=heading-link href=#hosting><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><h3 id=cloud>Cloud
<a class=heading-link href=#cloud><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><ul><li><a href=https://www.cerebrium.ai/>https://www.cerebrium.ai/</a> - makes it easier to train, deploy and monitor machine learning models with just a few lines of code - Serverless GPU Model Deployment</li><li><a href=https://cohere.ai/>https://cohere.ai/</a> - build high performance, secure LLM for the enterprise - powerful capabilities, like content generation, summarization, and search</li><li><a href=https://replicate.com/>https://replicate.com/</a> - Run models in the cloud at scale.</li></ul><h3 id=decentralized>Decentralized
<a class=heading-link href=#decentralized><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><ul><li><a href=https://petals.dev/>Petals</a> - Run large language models at home, BitTorrent‑style - <a href=https://github.com/bigscience-workshop/petals>Repo</a></li></ul><h3 id=local>Local
<a class=heading-link href=#local><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><ul><li><a href=https://mlc.ai/mlc-llm/>MLC LLM</a> - LLM on iPhone - <a href="https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone">App Store</a> - <a href=https://github.com/mlc-ai/mlc-llm>Repository</a></li><li><a href=https://github.com/go-skynet/LocalAI>LocalAI</a> - Self-hosted, community-driven, local OpenAI-compatible API. (&mldr;) No GPU required&mldr;</li><li><a href=https://github.com/ggerganov/llama.cpp>llama.cpp</a><ul><li><a href=https://cezimbra.me/anotacoes/python/>Python</a> bindings - <a href=https://github.com/abetlen/llama-cpp-python>Repo</a></li><li><a href=https://replicate.com/blog/run-llama-locally>A comprehensive guide to running Llama 2 locally</a></li></ul></li></ul><h2 id=image-generation>Image Generation
<a class=heading-link href=#image-generation><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://openai.com/dall-e-2/>DALL-E 2</a><ul><li><a href=https://pitch.com/v/DALL-E-prompt-book-v1-tmd33y>Prompt book</a></li><li><a href=https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#>DALL·E 2 Prompt Engineering Guide</a></li><li><a href=https://dosinga.medium.com/use-dall-e-to-create-infinite-zoom-movies-234fb72c85ab>Use DALL-E to create infinite zoom movies</a></li></ul></li><li><a href=https://beta.dreamstudio.ai/>DreamStudio</a></li><li><a href=https://cezimbra.me/anotacoes/midjourney/>Midjourney</a></li><li><a href=https://github.com/CompVis/stable-diffusion>Stable Diffusion</a><ul><li><a href=https://huggingface.co/spaces/stabilityai/stable-diffusion>Demo Hugging Face</a></li><li><a href=https://stablediffusionweb.com/>Online</a></li><li>Outpainting on an infinite canvas - <a href=https://twitter.com/lkwq007/status/1576078349503373312>Tweet</a> and <a href=https://github.com/lkwq007/stablediffusion-infinity>Sourcecode</a></li></ul></li><li><a href=https://www.tryleap.ai/>https://www.tryleap.ai/</a></li></ul><h2 id=langchain>LangChain
<a class=heading-link href=#langchain><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://langchain.readthedocs.io/en/latest/>https://langchain.readthedocs.io/en/latest/</a> - <a href=https://cezimbra.me/anotacoes/python/>Python</a> lib to develop AI applications - PromptTemplate, LLMs interface, etc.</li><li>Docs: <a href=https://langchain.readthedocs.io/en/latest/>https://langchain.readthedocs.io/en/latest/</a></li><li><strong>Agents</strong> use an LLM to determine which actions to take and in what order.</li><li>Pros<ul><li>Builtin Chain serialization - <a href=https://python.langchain.com/en/latest/modules/chains/generic/serialization.htm>https://python.langchain.com/en/latest/modules/chains/generic/serialization.htm</a></li></ul></li><li><a href=https://github.com/yoheinakajima/babyagi>https://github.com/yoheinakajima/babyagi</a> - BabyAGI #Pinecone</li></ul><h2 id=mpt>MPT
<a class=heading-link href=#mpt><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://www.mosaicml.com/blog/mpt-7b>Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs</a></li><li><a href=https://github.com/mosaicml/composer>https://github.com/mosaicml/composer</a> - PyTorch library that enables you to train neural networks faster, at lower cost, and to higher accuracy - <a href=https://cezimbra.me/anotacoes/python/>Python</a></li><li><a href=https://github.com/mosaicml/streaming>https://github.com/mosaicml/streaming</a> - make training on large datasets from cloud storage as fast, cheap, and scalable as possible. <a href=https://cezimbra.me/anotacoes/python/>Python</a></li><li><a href=https://github.com/mosaicml/llm-foundry>https://github.com/mosaicml/llm-foundry</a></li></ul><h2 id=prompt-engineering>Prompt Engineering
<a class=heading-link href=#prompt-engineering><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://github.com/microsoft/prompt-engine>https://github.com/microsoft/prompt-engine</a> - <a href=https://cezimbra.me/anotacoes/javascript/>Javascript</a> lib for creating and maintaining prompts for Large Language Models #OpenSource</li><li><a href=https://github.com/microsoft/guidance/>https://github.com/microsoft/guidance/</a> - A guidance language for controlling large language models <a href=https://cezimbra.me/anotacoes/python/>Python</a> #OpenSource</li><li><a href=https://gist.github.com/Hellisotherpeople/45c619ee22aac6865ca4bb328eb58faf>https://gist.github.com/Hellisotherpeople/45c619ee22aac6865ca4bb328eb58faf</a> - You probably don&rsquo;t know how to do Prompt Engineering</li><li><a href=https://eyurtsev.github.io/kor/index.html>https://eyurtsev.github.io/kor/index.html</a> - a half-baked prototype that “helps” you extract structured data from text using LLMs - <a href=https://cezimbra.me/anotacoes/python/>Python</a></li></ul><h2 id=speech-recognition>Speech Recognition
<a class=heading-link href=#speech-recognition><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://github.com/openai/whisper>https://github.com/openai/whisper</a> - general-purpose speech recognition model<ul><li><a href=https://github.com/ggerganov/whisper.cpp>https://github.com/ggerganov/whisper.cpp</a> - runs on the CPU<ul><li><a href=https://huggingface.co/ggerganov/whisper.cpp/tree/main>https://huggingface.co/ggerganov/whisper.cpp/tree/main</a> - models</li></ul></li></ul></li></ul></article></section></div><footer class=footer><section class=container>©
2023
Lucas Cezimbra
·
<a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
<script src=/scripts/jquery-3.6.1.min.min.a5bd2eaef424674aaf1fbce2006e5c6d090807fad5f20dead81f060bb8e37c04.js integrity="sha256-pb0urvQkZ0qvH7ziAG5cbQkIB/rV8g3q2B8GC7jjfAQ="></script>
<script src=/scripts/jquery.dataTables.min.min.f90ab97ce924f89a65ac5093e70bfd7feed67d5d3381bccedfdb6d6a3e03cb93.js integrity="sha256-+Qq5fOkk+JplrFCT5wv9f+7WfV0zgbzO39ttaj4Dy5M="></script>
<script data-goatcounter=https://cezimbra.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>